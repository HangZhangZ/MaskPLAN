{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Embedding, Add, Flatten\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU, Reshape\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'img_mix' # img_room_vq img_loc_vq img_boundary\n",
    "color = 'rgba' # rgba rgb\n",
    "dirc = 'LR_5564' # S_5564 L_5564 R_5564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddaf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n",
    "\n",
    "def variance(image):\n",
    "    image = tf.experimental.numpy.var(image)\n",
    "    return image\n",
    "\n",
    "train_data_gen = tf.keras.utils.image_dataset_from_directory(\n",
    "    '%s' % (task),\n",
    "    labels=None,\n",
    "    label_mode=None,\n",
    "    class_names=None,\n",
    "    color_mode=\"%s\" % (color),\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=7)\n",
    "\n",
    "dataset_train = train_data_gen.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1744cc9",
   "metadata": {},
   "source": [
    "Variance (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.zeros(shape=((32, 128, 128, 4)),dtype=np.int32)\n",
    "for i,j in enumerate(dataset_train):\n",
    "    if i == 0:\n",
    "        aa = j\n",
    "    elif 0 < i < 50000:\n",
    "        aa = np.vstack((aa,j))\n",
    "\n",
    "data_variance = np.var(aa[1:])\n",
    "data_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(layers.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        # The `beta` parameter is best kept between [0.25, 2] as per the paper.\n",
    "        self.beta = beta\n",
    "\n",
    "        # Initialize the embeddings which we will quantize.\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact.\n",
    "        input_shape = tf.shape(x)\n",
    "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
    "\n",
    "        # Quantization.\n",
    "        encoding_indices = self.get_code_indices(flattened)\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - x) ** 2)\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
    "        self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator.\n",
    "        quantized = x + tf.stop_gradient(quantized - x)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate L2-normalized distance between the inputs and the codes.\n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        distances = (\n",
    "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
    "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
    "            - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances.\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices\n",
    "\n",
    "def ResBlock(inputs,hidden):\n",
    "    x = layers.Conv2D(hidden, 3, padding=\"same\",strides=1, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(hidden, 3, padding=\"same\",strides=1)(x)\n",
    "    x = layers.Add()([inputs, x])\n",
    "    return x\n",
    "\n",
    "# Upsampling Block\n",
    "def Upsampling(inputs, hidden, factor=1):\n",
    "    x = layers.Conv2D(hidden * (factor ** 2), 3, padding=\"same\")(inputs)\n",
    "    x = layers.Conv2D(hidden * (factor ** 2), 3, padding=\"same\")(x)\n",
    "    x = layers.Add()([inputs, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fa5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "encoder_inputs = Input(shape=(128, 128, 4),name=\"input\",dtype=\"float32\")\n",
    "x = layers.Conv2D(64, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = ResBlock(x,64)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\")(x)\n",
    "x = ResBlock(x,128)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(256, 3, activation=\"LeakyReLU\", strides=3, padding=\"valid\")(x)\n",
    "x = ResBlock(x,256)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(512, 3, activation=\"LeakyReLU\", strides=2, padding='same')(x)\n",
    "x = ResBlock(x,512)\n",
    "x = layers.BatchNormalization()(x)\n",
    "encoder_outputs = layers.Conv2D(latent_dim, 1, activation=\"LeakyReLU\",strides=1, padding=\"same\")(x)\n",
    "\n",
    "encoder = Model(encoder_inputs,encoder_outputs, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = Input(shape=encoder.output.shape[1:])\n",
    "\n",
    "x = layers.Conv2DTranspose(512, 3, activation=\"LeakyReLU\", strides=1, padding=\"same\")(latent_inputs)\n",
    "x = layers.Conv2DTranspose(512, 3, activation=\"LeakyReLU\", strides=3, padding=\"valid\",output_padding=1)(x)\n",
    "x = Upsampling(x, 512)\n",
    "x = layers.Conv2DTranspose(256, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\")(x)\n",
    "x = Upsampling(x, 256)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\")(x)\n",
    "x = Upsampling(x, 128)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\")(x)\n",
    "x = Upsampling(x, 64)\n",
    "\n",
    "decoder_outputs = layers.Conv2DTranspose(4, 3, padding=\"same\",name=\"output\",activation='sigmoid')(x)#\n",
    "decoder = Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vqvae(latent_dim=64, num_embeddings=64):\n",
    "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
    "    encod = encoder\n",
    "    decod = decoder\n",
    "    inputs = Input(shape=(128, 128, 4))\n",
    "    encoder_outputs = encod(inputs)\n",
    "    quantized_latents = vq_layer(encoder_outputs)\n",
    "    reconstructions = decod(quantized_latents)\n",
    "    return Model(inputs, reconstructions, name=\"vq_vae\")\n",
    "\n",
    "get_vqvae().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAETrainer(Model):\n",
    "    def __init__(self, train_variance, latent_dim=64, num_embeddings=64, **kwargs):\n",
    "        super(VQVAETrainer, self).__init__(**kwargs)\n",
    "        self.train_variance = train_variance\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        self.vqvae = get_vqvae(self.latent_dim, self.num_embeddings)\n",
    "\n",
    "        self.total_loss_tracker = tensorflow.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tensorflow.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.vq_loss_tracker = tensorflow.keras.metrics.Mean(name=\"vq_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.vq_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Outputs from the VQ-VAE.\n",
    "            reconstructions = self.vqvae(x)\n",
    "\n",
    "            # Calculate the losses.\n",
    "            reconstruction_loss = (\n",
    "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
    "            )\n",
    "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
    "\n",
    "        # Backpropagation.\n",
    "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
    "\n",
    "        # Loss tracking.\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
    "\n",
    "        # Log results.\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(tensorflow.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print(\"\\nEpoch %05d: Learning rate is %6.6f.\" % (epoch, scheduled_lr))\n",
    "\n",
    "LR_SCHEDULE = [\n",
    "    (0, 1e-6),\n",
    "    (25, 5e-7)]\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='reconstruction_loss', factor=0.5,\n",
    "                              patience=1, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541d4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('CoPLAN',\"loss\",0,True,\n",
    "    True,\"min\",\"epoch\",options=None,initial_value_threshold=None,)\n",
    "vqvae_trainer = VQVAETrainer(0.1)\n",
    "vqvae_trainer.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=1e-5))#learning_rate=1e-4\n",
    "vqvae_trainer.fit(dataset_train,epochs=200,callbacks=[reduce_lr])#CustomLearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "encoder = vqvae_trainer.vqvae.get_layer(\"encoder\")\n",
    "quantizer = vqvae_trainer.vqvae.get_layer(\"vector_quantizer\")\n",
    "decoder = vqvae_trainer.vqvae.get_layer(\"decoder\")\n",
    "def show_subplot(original, reconstructed):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original[:,:,0])\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reconstructed[:,:,0])\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "img_path = r'%s\\%d.png' % (task,18)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    img_path,\n",
    "    grayscale=False,\n",
    "    color_mode='%s' % (color),\n",
    "    target_size=None,\n",
    ")\n",
    "x1 = image.img_to_array(img)\n",
    "x = x1/255.\n",
    "x2 = np.expand_dims(x, axis=0)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "encoded_outputs = encoder.predict(x2)\n",
    "code = quantizer(encoded_outputs)\n",
    "reconstructions_test = decoder.predict(code).reshape((128, 128, 4))\n",
    "\n",
    "show_subplot(x, reconstructions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80306164",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_outputs = encoder.predict(x2)\n",
    "flat_enc_outputs = encoded_outputs.reshape(-1, encoded_outputs.shape[-1])\n",
    "codebook_indices = quantizer.get_code_indices(flat_enc_outputs)\n",
    "codebook_indices = codebook_indices.numpy().reshape(encoded_outputs.shape[:-1])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x)\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(codebook_indices[0])\n",
    "plt.title(\"Code\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('VQ_Pretrained/mix_5564/vqvae_en/encoder', exist_ok=True)\n",
    "os.makedirs('VQ_Pretrained/mix_5564/vqvae_de/decoder', exist_ok=True)\n",
    "os.makedirs('VQ_Pretrained/mix_5564/vqvae_q', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('VQ_Pretrained/mix_5564/vqvae_en/encoder.keras', overwrite=True, save_format=None, options=None)\n",
    "decoder.save('VQ_Pretrained/mix_5564/vqvae_de/decoder.keras', overwrite=True, save_format=None, options=None)\n",
    "np.save('VQ_Pretrained/mix_5564/vqvae_q/quantizer.npy',quantizer.embeddings.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f20985",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = load_model('VQ_Pretrained/mix_5564/vqvae_en/encoder.keras')\n",
    "decoder = load_model('VQ_Pretrained/mix_5564/vqvae_de/decoder.keras')\n",
    "vq_value = np.load('VQ_Pretrained/mix_5564/vqvae_q/quantizer.npy')\n",
    "quantizer = VectorQuantizer(64, 64)\n",
    "quantizer.embeddings = tf.Variable(\n",
    "            initial_value=vq_value,\n",
    "            trainable=False,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13268d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "np_codebooksL = np.zeros((80788,10,25)).astype(np.int32)\n",
    "np_codebooksR = np.zeros((80788,10,25)).astype(np.int32)\n",
    "\n",
    "type_in = np.load('Processed_data/T_type_ada.npz')['type_in']\n",
    "type_in_new = np.insert(type_in,9,0,axis = 1)\n",
    "for i in range(80788):\n",
    "    for j,k in enumerate(type_in_new[i]):\n",
    "\n",
    "        img_pathL = r'img_loc_sqe\\%d\\%d.png' % (j,i)\n",
    "\n",
    "        img = image.load_img(img_pathL, color_mode='rgba', target_size=(128, 128))\n",
    "        x1 = image.img_to_array(img)\n",
    "        x = x1/255.\n",
    "        x2 = np.expand_dims(x, axis=0)\n",
    "\n",
    "        encoded_outputs = encoder.predict(x2)\n",
    "        flat_enc_outputs = encoded_outputs.reshape(-1, encoded_outputs.shape[-1])\n",
    "        codebook_indices = quantizer.get_code_indices(flat_enc_outputs).numpy()\n",
    "        np_codebooksL[i,j] = codebook_indices\n",
    "\n",
    "        img_pathR = r'img_room_sqe\\%d\\%d.png' % (j,i)\n",
    "\n",
    "        img2 = image.load_img(img_pathR, color_mode='rgba', target_size=(128, 128))\n",
    "        x11 = image.img_to_array(img2)\n",
    "        xx = x11/255.\n",
    "        x22 = np.expand_dims(xx, axis=0)\n",
    "\n",
    "        encoded_outputs2 = encoder.predict(x22)\n",
    "        flat_enc_outputs2 = encoded_outputs2.reshape(-1, encoded_outputs2.shape[-1])\n",
    "        codebook_indices2 = quantizer.get_code_indices(flat_enc_outputs2).numpy()\n",
    "        np_codebooksR[i,j] = codebook_indices2\n",
    "        if k == 0:\n",
    "            break\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Processed_data/RPLAN_L_code.npy',np_codebooksL.astype(np.int32))\n",
    "np.save('Processed_data/RPLAN_R_code.npy',np_codebooksR.astype(np.int32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
